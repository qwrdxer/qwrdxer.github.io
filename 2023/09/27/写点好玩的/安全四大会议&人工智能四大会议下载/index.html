<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>安全四大会议&amp;人工智能四大会议下载 | qwrdxer &#39;s blog</title>
  <meta name="keywords" content="">
  <meta name="description" content="安全四大会议&amp;人工智能四大会议下载 | qwrdxer &#39;s blog">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta property="og:type" content="website">
<meta property="og:title" content="About">
<meta property="og:url" content="https://qwrdxer.github.io/about/index.html">
<meta property="og:site_name" content="qwrdxer &#39;s blog">
<meta property="og:locale">
<meta property="article:published_time" content="2025-08-10T03:50:56.671Z">
<meta property="article:modified_time" content="2025-08-10T03:50:56.671Z">
<meta property="article:author" content="qwrdxer">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/github.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 5.4.2"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/avatar.jpg"/>
</a>
<div class="author">
    <span>qwrdxer</span>
</div>

<div class="icon">
    
        
            <a title="rss"
               href="/atom.xml"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-rss"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="github"
               href="https://github.com/qwrdxer"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-github"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="zhihu"
               href="https://www.zhihu.com/people/yyc-96-55-3"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-zhihu"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="csdn"
               href="https://blog.csdn.net/qwrdxer?type=blog"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-csdn"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="email"
               href="mailto:1944270374@qq.com"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-email"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="qq"
               href="http://wpa.qq.com/msgrd?v=3&uin=1944270374&site=qq&menu=yes"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-qq"></use>
                    </svg>
                
            </a>
        
    
</div>





<ul>
    <li>
        <div class="all active" data-rel="全部文章">全部文章
            
                <small>(58)</small>
            
        </div>
    </li>
    
        
            
                
    <li>
        <div data-rel="杂项">
            
            杂项
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="编程语言">
            <i class="fold iconfont icon-right"></i>
            编程语言
            <small>(4)</small>
        </div>
        
            <ul class="sub hide">
                
                    
    <li>
        <div data-rel="编程语言&lt;---&gt;C++">
            
            C++
            <small>(1)</small>
        </div>
        
    </li>

                
                    
    <li>
        <div data-rel="编程语言&lt;---&gt;Go">
            
            Go
            <small>(1)</small>
        </div>
        
    </li>

                
                    
    <li>
        <div data-rel="编程语言&lt;---&gt;Rust">
            
            Rust
            <small>(2)</small>
        </div>
        
    </li>

                
            </ul>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="操作系统">
            
            操作系统
            <small>(2)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="代码分析">
            
            代码分析
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="环境配置">
            
            环境配置
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="脚本">
            
            脚本
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="开发工具">
            
            开发工具
            <small>(4)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="论文阅读">
            <i class="fold iconfont icon-right"></i>
            论文阅读
            <small>(1)</small>
        </div>
        
            <ul class="sub hide">
                
                    
    <li>
        <div data-rel="论文阅读&lt;---&gt;人工智能">
            
            人工智能
            <small>(1)</small>
        </div>
        
    </li>

                
            </ul>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="爬虫">
            
            爬虫
            <small>(3)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="区块链">
            
            区块链
            <small>(2)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="人工智能">
            <i class="fold iconfont icon-right"></i>
            人工智能
            <small>(4)</small>
        </div>
        
            <ul class="sub hide">
                
                    
    <li>
        <div data-rel="人工智能&lt;---&gt;FASTAI">
            
            FASTAI
            <small>(4)</small>
        </div>
        
    </li>

                
            </ul>
        
    </li>

            
        
    
        
            
        
    
        
            
                
    <li>
        <div data-rel="日志">
            
            日志
            <small>(3)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="渗透测试篇">
            
            渗透测试篇
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="数据库">
            
            数据库
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="算法">
            
            算法
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="写点好玩的">
            
            写点好玩的
            <small>(6)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="一些奇怪的bug">
            
            一些奇怪的bug
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="以太坊">
            
            以太坊
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="Agent">
            
            Agent
            <small>(4)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="AI安全">
            
            AI安全
            <small>(2)</small>
        </div>
        
    </li>

            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
                
    <li>
        <div data-rel="LLM">
            
            LLM
            <small>(8)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="MCP">
            
            MCP
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
        
    
        
            
                
    <li>
        <div data-rel="web安全工具篇">
            
            web安全工具篇
            <small>(3)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="web安全漏洞篇">
            
            web安全漏洞篇
            <small>(2)</small>
        </div>
        
    </li>

            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
            
            
            
    </div>
    <div>
        
            <a class="about  hasFriend  site_url"
               
               href="/about">关于</a>
        
        <a style="width: 50%"
                
                                           class="friends">友链</a>
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="58">
<input type="hidden" id="yelog_site_word_count" value="176.4k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>报错解决</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>工具开发</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>工具使用</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>环境配置</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>脚本</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>开发</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>深度学习</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>渗透测试</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>通讯协议</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>文件包含</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Agent</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>bash</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>docker</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>FASTAI</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>GPT</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Josephus</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>linux</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>LLM</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>MCP</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Memory</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Multi-Agent</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>MySQL</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>python</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>shell</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Swarm</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>web漏洞</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>WordPress</a>
            </li>
        
    </div>

</div>

    
    <div id="local-search-result">

    </div>
    
    <nav id="title-list-nav">
        
        
        <a  class="全部文章 AI安全 "
           href="/2025/08/10/AI%E5%AE%89%E5%85%A8/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%98%B2%E7%81%AB%E5%A2%99-%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="大模型防火墙-数据工程">大模型防火墙-数据工程</span>
            <span class="post-date" title="2025-08-10 22:42:14">2025/08/10</span>
        </a>
        
        
        <a  class="全部文章 AI安全 "
           href="/2025/08/10/AI%E5%AE%89%E5%85%A8/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%98%B2%E7%81%AB%E5%A2%99-overview/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="大模型防火墙-overview">大模型防火墙-overview</span>
            <span class="post-date" title="2025-08-10 12:36:18">2025/08/10</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/05/11/LLM/LLM%E5%AE%89%E5%85%A8%E4%BE%8B%E5%AD%90.%20%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2%E3%80%81MCP%E5%AE%89%E5%85%A8%E3%80%81%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%8E%B7%E5%8F%96/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="LLM安全例子. 联网搜索、MCP安全、系统提示词获取、文生图越狱等">LLM安全例子. 联网搜索、MCP安全、系统提示词获取、文生图越狱等</span>
            <span class="post-date" title="2025-05-11 17:00:27">2025/05/11</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/04/17/LLM/%E5%A4%A7%E6%A8%A1%E5%9E%8B%20System%20Prompt%E6%90%9C%E9%9B%86/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="大模型 System Prompt搜集">大模型 System Prompt搜集</span>
            <span class="post-date" title="2025-04-17 17:38:23">2025/04/17</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/04/15/LLM/unsloth%20%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE&GRPO%E6%B5%81%E7%A8%8B%E8%B7%91%E9%80%9A/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="unsloth 环境配置&amp;GRPO流程跑通">unsloth 环境配置&amp;GRPO流程跑通</span>
            <span class="post-date" title="2025-04-15 13:26:12">2025/04/15</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/04/12/LLM/Llama%20Factory%20%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%20LLM%E8%B6%8A%E7%8B%B1%E7%9B%B8%E5%85%B3%E5%A4%A7%E6%A8%A1%E5%9E%8B/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Llama Factory 微调一个 LLM越狱相关大模型">Llama Factory 微调一个 LLM越狱相关大模型</span>
            <span class="post-date" title="2025-04-12 13:56:52">2025/04/12</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/04/10/LLM/Qwen2.5-7b%20Lora%E5%BE%AE%E8%B0%83-peft%E7%AF%87/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Qwen2.5-7b Lora微调-peft篇">Qwen2.5-7b Lora微调-peft篇</span>
            <span class="post-date" title="2025-04-10 14:32:36">2025/04/10</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/04/07/LLM/%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA25M%E7%9A%84GPT2%E6%A8%A1%E5%9E%8B/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="预训练一个25M的GPT2模型">预训练一个25M的GPT2模型</span>
            <span class="post-date" title="2025-04-07 14:19:54">2025/04/07</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/04/06/LLM/Tokenizer%20%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Tokenizer 从零开始训练">Tokenizer 从零开始训练</span>
            <span class="post-date" title="2025-04-06 20:50:21">2025/04/06</span>
        </a>
        
        
        <a  class="全部文章 LLM "
           href="/2025/04/06/LLM/GPT2%20%E6%89%8B%E6%92%95%20%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="GPT2 手撕 模型代码分析">GPT2 手撕 模型代码分析</span>
            <span class="post-date" title="2025-04-06 14:14:30">2025/04/06</span>
        </a>
        
        
        <a  class="全部文章 Agent "
           href="/2025/03/22/Agent/multi-agent%E4%B8%AD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"
           data-tag="Agent,Multi-Agent"
           data-author="" >
            <span class="post-title" title="multi-agent中的设计模式">multi-agent中的设计模式</span>
            <span class="post-date" title="2025-03-22 14:46:50">2025/03/22</span>
        </a>
        
        
        <a  class="全部文章 Agent "
           href="/2025/03/22/Agent/autogen-core%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"
           data-tag="Agent,Multi-Agent"
           data-author="" >
            <span class="post-title" title="autogen-core学习记录">autogen-core学习记录</span>
            <span class="post-date" title="2025-03-22 14:42:21">2025/03/22</span>
        </a>
        
        
        <a  class="全部文章 MCP "
           href="/2025/03/12/MCP/MCP(Model%20Context%20Protocol)%20%E7%AE%80%E4%BB%8B/"
           data-tag="MCP,通讯协议,LLM"
           data-author="" >
            <span class="post-title" title="MCP(Model Context Protocol) 简介">MCP(Model Context Protocol) 简介</span>
            <span class="post-date" title="2025-03-12 15:47:27">2025/03/12</span>
        </a>
        
        
        <a  class="全部文章 Agent "
           href="/2025/03/10/Agent/autogen%E6%8F%90%E9%AB%98%E4%B9%8BAgentChat%20Advanced%E9%83%A8%E5%88%86/"
           data-tag="Agent,Multi-Agent,Memory,Swarm"
           data-author="" >
            <span class="post-title" title="autogen提高之AgentChat Advanced部分">autogen提高之AgentChat Advanced部分</span>
            <span class="post-date" title="2025-03-10 21:35:41">2025/03/10</span>
        </a>
        
        
        <a  class="全部文章 Agent "
           href="/2025/03/08/Agent/autogen%E5%85%A5%E9%97%A8%E4%B9%8Bagentchat/"
           data-tag="Agent,Multi-Agent"
           data-author="" >
            <span class="post-title" title="autogen入门之autochat">autogen入门之autochat</span>
            <span class="post-date" title="2025-03-08 20:23:19">2025/03/08</span>
        </a>
        
        
        <a  class="全部文章 开发工具 "
           href="/2024/02/26/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/logseq%E4%BD%BF%E7%94%A8/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="logseq使用">logseq使用</span>
            <span class="post-date" title="2024-02-26 10:47:48">2024/02/26</span>
        </a>
        
        
        <a  class="全部文章 区块链 "
           href="/2024/01/21/%E5%8C%BA%E5%9D%97%E9%93%BE/hardhat%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E6%B5%81%E7%A8%8B/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="hardhat智能合约流程">hardhat智能合约流程</span>
            <span class="post-date" title="2024-01-21 15:20:03">2024/01/21</span>
        </a>
        
        
        <a  class="全部文章 算法 "
           href="/2024/01/17/%E7%AE%97%E6%B3%95/Josephus%20Problem/"
           data-tag="Josephus"
           data-author="" >
            <span class="post-title" title="Josephus Problem">Josephus Problem</span>
            <span class="post-date" title="2024-01-17 11:49:36">2024/01/17</span>
        </a>
        
        
        <a  class="全部文章 区块链 "
           href="/2024/01/08/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="fabric环境配置">fabric环境配置</span>
            <span class="post-date" title="2024-01-08 18:47:43">2024/01/08</span>
        </a>
        
        
        <a  class="全部文章 爬虫 "
           href="/2023/12/22/%E7%88%AC%E8%99%AB/CF%E7%9B%BE%E7%BB%95%E8%BF%87(NodeJs%E7%89%88)/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="CF盾绕过(NodeJs版)">CF盾绕过(NodeJs版)</span>
            <span class="post-date" title="2023-12-22 20:11:48">2023/12/22</span>
        </a>
        
        
        <a  class="全部文章 以太坊 "
           href="/2023/10/19/%E4%BB%A5%E5%A4%AA%E5%9D%8A/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E9%83%A8%E5%88%86%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B5%85%E6%9E%90/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="以太坊部分知识点浅析">以太坊部分知识点浅析</span>
            <span class="post-date" title="2023-10-19 16:10:05">2023/10/19</span>
        </a>
        
        
        <a  class="全部文章 日志 "
           href="/2023/10/12/%E6%97%A5%E5%BF%97/%E9%93%BE%E6%8E%A5%E8%AE%B0%E5%BD%95/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="链接记录">链接记录</span>
            <span class="post-date" title="2023-10-12 19:40:28">2023/10/12</span>
        </a>
        
        
        <a  class="全部文章 爬虫 "
           href="/2023/10/06/%E7%88%AC%E8%99%AB/go-rod%E5%AD%A6%E4%B9%A0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="go-rod学习">go-rod学习</span>
            <span class="post-date" title="2023-10-06 11:22:48">2023/10/06</span>
        </a>
        
        
        <a  class="全部文章 爬虫 "
           href="/2023/10/06/%E7%88%AC%E8%99%AB/Go%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Go实现一个爬虫">Go实现一个爬虫</span>
            <span class="post-date" title="2023-10-06 11:10:43">2023/10/06</span>
        </a>
        
        
        <a  class="全部文章 代码分析 "
           href="/2023/10/05/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/RustScan%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="RustScan源代码分析">RustScan源代码分析</span>
            <span class="post-date" title="2023-10-05 19:28:59">2023/10/05</span>
        </a>
        
        
        <a  class="全部文章 一些奇怪的bug "
           href="/2023/10/02/%E4%B8%80%E4%BA%9B%E5%A5%87%E6%80%AA%E7%9A%84bug/bug%E8%AE%B0%E5%BD%95&%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="bug记录&amp;解决方法">bug记录&amp;解决方法</span>
            <span class="post-date" title="2023-10-02 16:05:12">2023/10/02</span>
        </a>
        
        
        <a  class="全部文章 论文阅读 人工智能 "
           href="/2023/10/01/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/OpenAI%E7%9A%84GPT%E5%8F%91%E5%B1%95/"
           data-tag="LLM,GPT"
           data-author="" >
            <span class="post-title" title="大模型论文">大模型论文</span>
            <span class="post-date" title="2023-10-01 22:17:21">2023/10/01</span>
        </a>
        
        
        <a  class="全部文章 编程语言 Rust "
           href="/2023/09/28/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Rust/Rust_lifetime/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Rust的生命周期">Rust的生命周期</span>
            <span class="post-date" title="2023-09-28 11:33:04">2023/09/28</span>
        </a>
        
        
        <a  class="全部文章 写点好玩的 "
           href="/2023/09/27/%E5%86%99%E7%82%B9%E5%A5%BD%E7%8E%A9%E7%9A%84/%E5%AE%89%E5%85%A8%E5%9B%9B%E5%A4%A7%E4%BC%9A%E8%AE%AE&%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%9B%E5%A4%A7%E4%BC%9A%E8%AE%AE%E4%B8%8B%E8%BD%BD/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="安全四大会议&amp;人工智能四大会议下载">安全四大会议&amp;人工智能四大会议下载</span>
            <span class="post-date" title="2023-09-27 20:47:28">2023/09/27</span>
        </a>
        
        
        <a  class="全部文章 编程语言 Rust "
           href="/2023/09/27/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Rust/The%20Rust%20Programming%20Language%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="The Rust Programming Language阅读笔记">The Rust Programming Language阅读笔记</span>
            <span class="post-date" title="2023-09-27 20:35:50">2023/09/27</span>
        </a>
        
        
        <a  class="全部文章 人工智能 FASTAI "
           href="/2023/09/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/FASTAI/FASTAI_3_%E5%A4%9AGPU%E8%AE%AD%E7%BB%83/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="FASTAI_3_多GPU训练">FASTAI_3_多GPU训练</span>
            <span class="post-date" title="2023-09-27 20:32:12">2023/09/27</span>
        </a>
        
        
        <a  class="全部文章 人工智能 FASTAI "
           href="/2023/09/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/FASTAI/FASTAI_2_Datasets%E3%80%81Pipeline%E3%80%81TfmdLists%E3%80%81Transform/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="FASTAI_2_Datasets、Pipeline、TfmdLists、Transform">FASTAI_2_Datasets、Pipeline、TfmdLists、Transform</span>
            <span class="post-date" title="2023-09-27 20:29:37">2023/09/27</span>
        </a>
        
        
        <a  class="全部文章 人工智能 FASTAI "
           href="/2023/09/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/FASTAI/FASTAI_1_%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%90%8CAPI%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/"
           data-tag="深度学习,FASTAI"
           data-author="" >
            <span class="post-title" title="FASTAI_1_使用不同API加载数据">FASTAI_1_使用不同API加载数据</span>
            <span class="post-date" title="2023-09-27 20:28:09">2023/09/27</span>
        </a>
        
        
        <a  class="全部文章 人工智能 FASTAI "
           href="/2023/09/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/FASTAI/FASTAI%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"
           data-tag="深度学习,FASTAI"
           data-author="" >
            <span class="post-title" title="FASTAI快速入门">FASTAI快速入门</span>
            <span class="post-date" title="2023-09-27 20:18:36">2023/09/27</span>
        </a>
        
        
        <a  class="全部文章 编程语言 C++ "
           href="/2023/01/10/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C++/C++%E5%85%A5%E9%97%A8/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="C++入门">C++入门</span>
            <span class="post-date" title="2023-01-10 11:30:50">2023/01/10</span>
        </a>
        
        
        <a  class="全部文章 写点好玩的 "
           href="/2022/04/27/%E5%86%99%E7%82%B9%E5%A5%BD%E7%8E%A9%E7%9A%84/%E5%88%86%E5%B8%83%E5%BC%8F%E6%89%AB%E6%8F%8F%E5%99%A8%E5%AE%9E%E7%8E%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="分布式扫描器实现">分布式扫描器实现</span>
            <span class="post-date" title="2022-04-27 11:43:42">2022/04/27</span>
        </a>
        
        
        <a  class="全部文章 数据库 "
           href="/2022/04/14/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb%E5%AD%A6%E4%B9%A0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="mongodb学习">mongodb学习</span>
            <span class="post-date" title="2022-04-14 09:31:33">2022/04/14</span>
        </a>
        
        
        <a  class="全部文章 写点好玩的 "
           href="/2022/04/10/%E5%86%99%E7%82%B9%E5%A5%BD%E7%8E%A9%E7%9A%84/Go%E7%BC%96%E5%86%99%E4%B8%80%E4%B8%AA%E7%AB%AF%E5%8F%A3%E6%89%AB%E6%8F%8F%E5%99%A8/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Go编写一个扫描器">Go编写一个扫描器</span>
            <span class="post-date" title="2022-04-10 14:34:18">2022/04/10</span>
        </a>
        
        
        <a  class="全部文章 写点好玩的 "
           href="/2022/04/09/%E5%86%99%E7%82%B9%E5%A5%BD%E7%8E%A9%E7%9A%84/%E6%83%B3%E6%B3%95%E8%AE%B0%E5%BD%95/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="想法记录">想法记录</span>
            <span class="post-date" title="2022-04-09 11:24:11">2022/04/09</span>
        </a>
        
        
        <a  class="全部文章 编程语言 Go "
           href="/2022/04/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/The%20Way%20To%20Go/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="The Way To Go">The Way To Go</span>
            <span class="post-date" title="2022-04-08 18:09:20">2022/04/08</span>
        </a>
        
        
        <a  class="全部文章 日志 "
           href="/2022/03/31/%E6%97%A5%E5%BF%97/%E5%B1%B1%E8%BF%98%E6%98%AF%E5%B1%B1,%E6%B0%B4%E8%BF%98%E6%98%AF%E6%B0%B4,%E4%BD%A0%E4%B8%8D%E8%83%BD%E6%B0%B8%E8%BF%9C%E6%98%AF%E9%82%A3%E4%B8%AA%E4%BD%A0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="山还是山,水还是水,你不能永远是那个你">山还是山,水还是水,你不能永远是那个你</span>
            <span class="post-date" title="2022-03-31 09:37:42">2022/03/31</span>
        </a>
        
        
        <a  class="全部文章 操作系统 "
           href="/2022/03/27/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20day11~day20/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="30天自制操作系统-学习笔记 day11~day20">30天自制操作系统-学习笔记 day11~day20</span>
            <span class="post-date" title="2022-03-27 09:49:33">2022/03/27</span>
        </a>
        
        
        <a  class="全部文章 日志 "
           href="/2022/03/21/%E6%97%A5%E5%BF%97/%E9%97%B2%E8%AF%AD%E6%9D%82%E8%AE%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="闲语杂记">闲语杂记</span>
            <span class="post-date" title="2022-03-21 12:51:18">2022/03/21</span>
        </a>
        
        
        <a  class="全部文章 写点好玩的 "
           href="/2022/03/15/%E5%86%99%E7%82%B9%E5%A5%BD%E7%8E%A9%E7%9A%84/freemarker%E6%93%8D%E6%8E%A7word/"
           data-tag="工具使用"
           data-author="" >
            <span class="post-title" title="freemarker操控word">freemarker操控word</span>
            <span class="post-date" title="2022-03-15 12:00:54">2022/03/15</span>
        </a>
        
        
        <a  class="全部文章 操作系统 "
           href="/2022/01/31/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="30天自制操作系统-学习笔记 day1~day10">30天自制操作系统-学习笔记 day1~day10</span>
            <span class="post-date" title="2022-01-31 10:57:39">2022/01/31</span>
        </a>
        
        
        <a  class="全部文章 杂项 "
           href="/2022/01/12/%E6%9D%82%E9%A1%B9/GITHUB%E6%94%B6%E9%9B%86/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="GITHUB收集">GITHUB收集</span>
            <span class="post-date" title="2022-01-12 20:07:03">2022/01/12</span>
        </a>
        
        
        <a  class="全部文章 写点好玩的 "
           href="/2022/01/11/%E5%86%99%E7%82%B9%E5%A5%BD%E7%8E%A9%E7%9A%84/web%E9%A1%B5%E9%9D%A2%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/"
           data-tag="渗透测试,工具开发"
           data-author="" >
            <span class="post-title" title="web页面密码爆破">web页面密码爆破</span>
            <span class="post-date" title="2022-01-11 10:21:34">2022/01/11</span>
        </a>
        
        
        <a  class="全部文章 web安全工具篇 "
           href="/2022/01/09/web%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7%E7%AF%87/Goby%E5%88%86%E6%9E%90/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Goby分析">Goby分析</span>
            <span class="post-date" title="2022-01-09 13:35:49">2022/01/09</span>
        </a>
        
        
        <a  class="全部文章 开发工具 "
           href="/2021/08/15/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Shell%E8%84%9A%E6%9C%AC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"
           data-tag="bash,脚本,shell,linux,开发"
           data-author="" >
            <span class="post-title" title="Shell脚本学习笔记">Shell脚本学习笔记</span>
            <span class="post-date" title="2021-08-15 11:19:55">2021/08/15</span>
        </a>
        
        
        <a  class="全部文章 渗透测试篇 "
           href="/2021/07/25/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E7%AF%87/%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/"
           data-tag="渗透测试,工具使用"
           data-author="" >
            <span class="post-title" title="信息收集">信息收集</span>
            <span class="post-date" title="2021-07-25 19:33:55">2021/07/25</span>
        </a>
        
        
        <a  class="全部文章 web安全漏洞篇 "
           href="/2021/05/11/web%E5%AE%89%E5%85%A8%E6%BC%8F%E6%B4%9E%E7%AF%87/SQL%E6%B3%A8%E5%85%A5%E7%9B%B8%E5%85%B3/"
           data-tag="web漏洞,MySQL"
           data-author="" >
            <span class="post-title" title="SQL注入相关">SQL注入相关</span>
            <span class="post-date" title="2021-05-11 15:23:06">2021/05/11</span>
        </a>
        
        
        <a  class="全部文章 web安全工具篇 "
           href="/2021/04/21/web%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7%E7%AF%87/nmap%E4%BD%BF%E7%94%A8/"
           data-tag="渗透测试,工具使用"
           data-author="" >
            <span class="post-title" title="nmap使用">nmap使用</span>
            <span class="post-date" title="2021-04-21 19:29:51">2021/04/21</span>
        </a>
        
        
        <a  class="全部文章 开发工具 "
           href="/2021/04/20/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/docker%E7%9B%B8%E5%85%B3/"
           data-tag="工具使用,脚本,docker"
           data-author="" >
            <span class="post-title" title="docker相关">docker相关</span>
            <span class="post-date" title="2021-04-20 13:49:50">2021/04/20</span>
        </a>
        
        
        <a  class="全部文章 web安全漏洞篇 "
           href="/2021/04/19/web%E5%AE%89%E5%85%A8%E6%BC%8F%E6%B4%9E%E7%AF%87/%E6%96%87%E4%BB%B6%E5%8C%85%E5%90%AB%E7%9B%B8%E5%85%B3/"
           data-tag="web漏洞,文件包含"
           data-author="" >
            <span class="post-title" title="文件包含漏洞相关">文件包含漏洞相关</span>
            <span class="post-date" title="2021-04-19 14:49:59">2021/04/19</span>
        </a>
        
        
        <a  class="全部文章 开发工具 "
           href="/2021/04/16/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hexo%E5%91%BD%E4%BB%A4/"
           data-tag="工具使用,脚本"
           data-author="" >
            <span class="post-title" title="hexo相关">hexo相关</span>
            <span class="post-date" title="2021-04-16 12:12:14">2021/04/16</span>
        </a>
        
        
        <a  class="全部文章 web安全工具篇 "
           href="/2021/04/16/web%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7%E7%AF%87/xray%E4%BD%BF%E7%94%A8/"
           data-tag="渗透测试,工具使用"
           data-author="" >
            <span class="post-title" title="xray使用">xray使用</span>
            <span class="post-date" title="2021-04-16 12:10:08">2021/04/16</span>
        </a>
        
        
        <a  class="全部文章 脚本 "
           href="/2021/04/15/%E8%84%9A%E6%9C%AC/some-script/"
           data-tag="bash,脚本,python"
           data-author="" >
            <span class="post-title" title="some script">some script</span>
            <span class="post-date" title="2021-04-15 11:23:33">2021/04/15</span>
        </a>
        
        
        <a  class="全部文章 环境配置 "
           href="/2021/04/15/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/centos%E9%83%A8%E7%BD%B2wordpress/"
           data-tag="linux,环境配置,报错解决,WordPress"
           data-author="" >
            <span class="post-title" title="centos部署wordpress">centos部署wordpress</span>
            <span class="post-date" title="2021-04-15 01:34:16">2021/04/15</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-写点好玩的/安全四大会议&amp;人工智能四大会议下载" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">安全四大会议&amp;人工智能四大会议下载</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            <i class="iconfont icon-category"></i>
            
            
            <a  data-rel="写点好玩的">写点好玩的</a>
            
        </span>
        
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2025-08-10 11:50:56'>2023-09-27 20:47</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:4.6k</span>
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD"><span class="toc-text">论文下载</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E9%A1%B6%E4%BC%9A"><span class="toc-text">安全顶会</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CCS"><span class="toc-text">CCS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#S-amp-P"><span class="toc-text">S&amp;P</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NDSS"><span class="toc-text">NDSS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#USENIX"><span class="toc-text">USENIX</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A1%B6%E4%BC%9A"><span class="toc-text">人工智能顶会</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDIJCAI-2023"><span class="toc-text">下载IJCAI 2023</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDICML-2023"><span class="toc-text">下载ICML 2023</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDAAAI-2023"><span class="toc-text">下载AAAI 2023</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NIPS%E6%B2%A1%E6%9C%892023%E7%9A%84"><span class="toc-text">NIPS没有2023的</span></a></li></ol></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-4 i,
    .toc-level-4 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="论文下载"><a href="#论文下载" class="headerlink" title="论文下载"></a>论文下载</h1><p><a target="_blank" rel="noopener" href="https://publications.cispa.saarland/view/year/2023.type.html">https://publications.cispa.saarland/view/year/2023.type.html</a></p>
<p>S&amp;P</p>
<p><a target="_blank" rel="noopener" href="https://www.ieee-security.org/TC/SP2023/program-papers.html">https://www.ieee-security.org/TC/SP2023/program-papers.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.ieee-security.org/TC/SP2022/program-papers.html">https://www.ieee-security.org/TC/SP2022/program-papers.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.ieee-security.org/TC/SP2021/program-papers.html">https://www.ieee-security.org/TC/SP2021/program-papers.html</a></p>
<p>CCS <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/proceedings/10.1145/3460120">https://dl.acm.org/doi/proceedings/10.1145/3460120</a></p>
<h2 id="安全顶会"><a href="#安全顶会" class="headerlink" title="安全顶会"></a>安全顶会</h2><h3 id="CCS"><a href="#CCS" class="headerlink" title="CCS"></a><strong>CCS</strong></h3><p>CCS大概下载30篇左右就会封禁IP两小时，因此每次被封禁IP后会sleep两小时继续爬</p>
<p>环境依赖:</p>
<ol>
<li>python库selenium、bs4、resquests</li>
<li>安装chrome对应版本的googledriver 并在init_driver()中chrome_driver_path  指定googledriver的位置</li>
</ol>
<p>使用方式：</p>
<pre><code class="python">python downloadccs.py --year 2021
</code></pre>
<p>首先爬取所有paper的 doi ，存储到data.json文件中， 然后根据data.json进行下载每次被封禁后sleep两小时继续下载。</p>
<p>爬取doi使用了selenium，后续的下载使用resquests、bs4库</p>
<pre><code class="python">from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
import re
import os
import argparse
import configparser
import datetime
import requests
from bs4 import BeautifulSoup
import json
import re
def generate_url_config(urls,driver):
    url_list=[]
    for url in urls:
        select_pdf_url(url,driver)
    return url_list
#使用requests库根据url 和pdf_name 发送httpget请求下载文文件
def download_pdf(url, pdf_name,year):
    # 使用正则表达式移除不适合用于文件名的特殊字符，将它们替换为空格
    pdf_name = re.sub(r&#39;[\\/:*?&quot;&lt;&gt;|]&#39;, &#39; &#39;, pdf_name)
    
    # 发送HTTP GET请求获取论文内容
    response = requests.get(url)
        # 创建下载目录
    download_dir = os.path.join(os.getcwd(), str(year))
    os.makedirs(download_dir, exist_ok=True)
    if response.status_code == 200:
        # 确定下载路径，你可以根据需要修改保存路径
        download_path = os.path.join(os.getcwd(), str(year), f&#39;&#123;pdf_name&#125;.pdf&#39;)
        time.sleep(5)
        if os.path.exists(download_path):
            print(f&#39;&#123;download_path&#125; 文件已存在&#39;)
            return 1
        else:
            print(f&#39;&#123;download_path&#125; 不存在,正在下载中&#39;)
            # 保存论文内容为PDF文件
            with open(download_path, &#39;wb&#39;) as pdf_file:
                pdf_file.write(response.content)
            print(f&#39;论文已下载到: &#123;download_path&#125;&#39;)
            return 1
    else:
        print(f&#39;无法下载论文，HTTP响应代码: &#123;response.status_code&#125;&#39;)
        return 0
#获取指定topic下的pdfurl，返回的是 pdf_name:pdf_url的多个键值对
def gather_pdf_url_from_topics(url,driver):
    
    print(&quot;正在访问指定的topic&#123;&#125;&quot;.format(url))
    pdf_urls=&#123;&#125;
    driver.get(url)
    #提取出文章的container .目前只要 research-article
    items = driver.find_elements(By.XPATH,&#39;.//div[@class=&quot;issue-item-container&quot;]&#39;)
    for item in items:
        paperType=item.find_element(By.XPATH,&#39;.//div[@class=&quot;issue-heading&quot;]&#39;).text.split(&quot;\\n&quot;)[0]
        print(paperType)
        if paperType ==&quot;RESEARCH-ARTICLE&quot;:
            #提取pdf的名字
            pdf_name=item.find_element(By.XPATH,&#39;.//h5[@class=&quot;issue-item__title&quot;]/a&#39;).text
            #提取出pdf链接
            pdf_url=item.find_element(By.XPATH,&#39;.//a[@class=&quot;btn--icon simple-tooltip__block--b red btn&quot;]&#39;).get_attribute(&quot;href&quot;)
            #下载PDF
            #download_pdf(pdf_url,pdf_name)
            #记录下来
            pdf_urls[pdf_name]=pdf_url
    print(pdf_urls)
    return pdf_urls
#初始化google_driver
def init_driver():
    #指定chromedirver的路径
    chrome_driver_path = &#39;chromedriver.exe&#39;
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument(&#39;--ignore-certificate-errors&#39;)
    chrome_options.add_argument(&#39;--ignore-certificate-errors-spki-list&#39;)
    chrome_options.add_experimental_option(&#39;excludeSwitches&#39;, [&#39;enable-logging&#39;])
    #下面这个可以指定下载路径
    #chrome_options.add_experimental_option(&quot;prefs&quot;, &#123;&quot;download.default_directory&quot;: &#39;E:\\Temp&#39;&#125;)
    driver = webdriver.Chrome()
    # 创建Chrome WebDriver实例
    chrome_service = ChromeService(executable_path=chrome_driver_path)
    driver = webdriver.Chrome(service=chrome_service,options=chrome_options)
    return driver

# 访问CCS历年会议的列表从中提取出指定年份会议的url
def get_conference_urls(year):
    # 发送 GET 请求获取页面内容
    url = &#39;&lt;https://dl.acm.org/conference/ccs/proceedings&gt;&#39;  # 将 URL 替换为你要访问的网页 URL
    response = requests.get(url)

    # 使用 BeautifulSoup 解析页面内容
    soup = BeautifulSoup(response.text, &#39;html.parser&#39;)

    # 查找所有匹配指定条件的 ul 标签
    divs = soup.find_all(&#39;div&#39;, class_=&#39;conference__title left-bordered-title&#39;)

    # 遍历 ul 标签并提取其中的所有 a 标签
    for div in divs:
        a_tags = div.find_all(&#39;a&#39;)
        for a_tag in a_tags:
            conf_year=a_tag.text.split(&quot;the&quot;)[1].split(&quot;ACM&quot;)[0].strip()
            if year==conf_year:
                return &quot;&lt;https://dl.acm.org&gt;&quot;+a_tag[&#39;href&#39;]
#从用户输入中获取要下载 的年份
def parser_year():
    current_year = datetime.datetime.now().year
    # 创建命令行参数解析器
    parser = argparse.ArgumentParser(description=&#39;处理年份对应的 PDF&#39;)
    # 添加命令行参数，并设置默认值为当前年份
    parser.add_argument(&#39;--year&#39;, type=str, default=current_year-1, help=&#39;要处理的年份，默认为当前年份&#39;)
    # 解析命令行参数
    args = parser.parse_args()
    # 获取命令行参数中的年份
    return str(args.year)

#遍历该CCS会议的所有topic
def select_topic_urls(ccs_url,driver):
        #创建一个sele

    driver.get(ccs_url)
    #等待get请求结束
    time.sleep(10)
    #获取所有topic 的url
    downSessions=driver.find_elements(By.XPATH,&#39;//a[@class=&quot;section__title accordion-tabbed__control left-bordered-title&quot;]&#39;)
    topic_urls=[]
    for session in downSessions:
        topic_urls.append(session.get_attribute(&quot;href&quot;))
    return topic_urls

if __name__ == &#39;__main__&#39;:
    download_year=parser_year() #，通过 --year指定，如2021
    #解析配置文件
    f=open(&#39;data.json&#39;, &#39;r&#39;)
    data = json.load(f)
    f.close()
    print(&quot;下载CCS会议年份:&quot;,download_year)
    if str(download_year) in data[&#39;conferences&#39;]:
        print(&quot;已有配置文件，直接下载！&quot;)
        for pdfs in data[&#39;conferences&#39;][download_year].items():
            pdf_url=pdfs[1][&#39;download_url&#39;]
            pdf_name=pdfs[0]
            if(data[&#39;conferences&#39;][download_year][pdf_name][&#39;isdownloaded&#39;]!=True):#检查是否已下载，为false则下载
                print(pdfs[1][&#39;download_url&#39;])
                if download_pdf(pdf_url,pdf_name,download_year):#如果能够正常下载则返回修改配置文件
                    data[&#39;conferences&#39;][download_year][pdf_name][&#39;isdownloaded&#39;]=True
                    with open(&#39;data.json&#39;, &#39;w&#39;) as updated_json_file: #更新配置文件
                        json.dump(data, updated_json_file, indent=4)
                else:
                    print(&quot;ip已被封禁，睡眠2小时 &quot;)
                    time.sleep(60*60*2)
                    

    else:
        driver=init_driver()
        data[&#39;conferences&#39;][download_year] = &#123;&#125;
        #更新配置文件
        pdfname_url=&#123;&#125;
        #获取目标年份CCS会议的url
        ccs_url=get_conference_urls(download_year)
        #获取CCS会议所有topic对应的url
        topic_urls=select_topic_urls(ccs_url,driver=driver)
        #存储 &#123;pdf_name,pdf_url&#125;
        for topic_url in topic_urls:
            pdfname_url.update(gather_pdf_url_from_topics(topic_url,driver=driver))
        target_year_data = data[&#39;conferences&#39;][download_year]
        #&#123;pdf_name,pdf_url&#125; 记入配置文件中

        for pdf_name, download_url in pdfname_url.items():
            target_year_data[pdf_name] = &#123;
                &quot;download_url&quot;: download_url,
                &quot;isdownloaded&quot;: False
                &#125;
        #写入配置文件中
        with open(&#39;data.json&#39;, &#39;w&#39;) as updated_json_file:
            json.dump(data, updated_json_file, indent=4)
############################################################################################################################
        print(&quot;配置文件导入完成！开始下载 &quot;)
        f=open(&#39;data.json&#39;, &#39;r&#39;)
        data = json.load(f)
        f.close()
        for pdfs in data[&#39;conferences&#39;][download_year].items():
            pdf_url=pdfs[1][&#39;download_url&#39;]
            pdf_name=pdfs[0]
            if(data[&#39;conferences&#39;][download_year][pdf_name][&#39;isdownloaded&#39;]!=True):#检查是否已下载，为false则下载
                print(pdfs[1][&#39;download_url&#39;])
                if download_pdf(pdf_url,pdf_name,download_year):
                    data[&#39;conferences&#39;][download_year][pdf_name][&#39;isdownloaded&#39;]=True
                    with open(&#39;data.json&#39;, &#39;w&#39;) as updated_json_file: #更新配置文件
                        json.dump(data, updated_json_file, indent=4)
                else:
                    print(&quot;ip已被封禁，退出下载 &quot;)
                    break
</code></pre>
<h3 id="S-amp-P"><a href="#S-amp-P" class="headerlink" title="S&amp;P"></a>S&amp;P</h3><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/xpl/conhome/1000646/all-proceedings">https://ieeexplore.ieee.org/xpl/conhome/1000646/all-proceedings</a>  这里按年份记录了下载地址 ，下面是近三年的下载地址</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/xpl/conhome/10179215/proceeding?isnumber=10179280&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=1">https://ieeexplore.ieee.org/xpl/conhome/10179215/proceeding?isnumber=10179280&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=1</a></p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/xpl/conhome/9833550/proceeding?isnumber=9833558&amp;sortType=vol-only-seq&amp;rowsPerPage=100&amp;pageNumber=1">https://ieeexplore.ieee.org/xpl/conhome/9833550/proceeding?isnumber=9833558&amp;sortType=vol-only-seq&amp;rowsPerPage=100&amp;pageNumber=1</a></p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/xpl/conhome/9519381/proceeding?isnumber=9519382&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=1">https://ieeexplore.ieee.org/xpl/conhome/9519381/proceeding?isnumber=9519382&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=1</a></p>
<p>使用selenium来下载</p>
<p>1.更新chrome ，浏览器输入chrome://version/ 查看 chrome版本</p>
<p><a target="_blank" rel="noopener" href="https://www.itbenet.com/wenz/223586.html">https://www.itbenet.com/wenz/223586.html</a></p>
<ol>
<li>下载对应版本的chrome-driver, 将exe文件解压出来</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://googlechromelabs.github.io/chrome-for-testing/#stable">https://googlechromelabs.github.io/chrome-for-testing/#stable</a></p>
<ol>
<li>修改脚本中的exe位置为自己的位置 chrome_driver_path = ‘F:\develop\chromedriver.exe’</li>
<li>pip install selenium</li>
</ol>
<pre><code class="python">sp2023=&quot;&lt;https://ieeexplore.ieee.org/xpl/conhome/10179215/proceeding?isnumber=10179280&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=1&gt;&quot;
sp2022=&quot;&lt;https://ieeexplore.ieee.org/xpl/conhome/9833550/proceeding?isnumber=9833558&amp;sortType=vol-only-seq&amp;rowsPerPage=100&amp;pageNumber=1&gt;&quot;
sp2021=&quot;&lt;https://ieeexplore.ieee.org/xpl/conhome/9519381/proceeding?isnumber=9519382&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=1&gt;&quot;
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

#分页下载，调用该函数会下载指定页面的pdf
def download_page(url,driver):
    driver.get(url)
    print(&quot;waiting for page loading&quot;)
    time.sleep(10)
    selectinput = driver.find_elements(By.XPATH,&#39;//div[@class=&quot;hide-mobile&quot;]//input[@class=&quot;ng-untouched ng-pristine ng-valid&quot;]&#39;)
    #选中pdf
    for input in selectinput:
        driver.execute_script(&quot;arguments[0].scrollIntoView();&quot;, input)#这里要模拟下拉一下，虽然不知道为啥 ，但是下拉就对了
        time.sleep(1) # 这里要sleep 1秒，否则点击有可能报错
        print(&quot;clicking&quot;)
        input.click()
    #print(len(selectinput))
    #点击下载按钮
    downloadbtn = driver.find_elements(By.XPATH,&#39;//button[@class=&quot;xpl-toggle-btn&quot; and normalize-space(text())=&quot;Download PDFs&quot;]&#39;)
    downloadbtn[0].click()

    #点击确认下载
    downloadbtn_accept=driver.find_element(By.XPATH,&#39;//button[contains(@class, &quot;downloadpdf-predl-proceed-button stats-SearchResults_BulkPDFDownload xpl-btn-primary&quot;)]&#39;)
    downloadbtn_accept.click()

    #获取loading
    loadingbtn=driver.find_element(By.XPATH,&#39;//i[contains(@class, &quot;fas&quot;) and contains(@class, &quot;fa-spinner&quot;) and contains(@class, &quot;fa-spin&quot;)]&#39;)
    #等待loading消失
    wait.until(EC.staleness_of(loadingbtn))

if __name__ == &#39;__main__&#39;:
    # 设置Chrome WebDriver的路径
    chrome_driver_path = &#39;F:\\develop\\chromedriver.exe&#39;
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument(&#39;--ignore-certificate-errors&#39;)
    chrome_options.add_argument(&#39;--ignore-certificate-errors-spki-list&#39;)
    chrome_options.add_experimental_option(&#39;excludeSwitches&#39;, [&#39;enable-logging&#39;])
    driver = webdriver.Chrome()
    # 创建Chrome WebDriver实例
    chrome_service = ChromeService(executable_path=chrome_driver_path)
    driver = webdriver.Chrome(service=chrome_service,options=chrome_options)
    wait = WebDriverWait(driver, 300)

    #首先解析出一共有多少pdf,然后分页下载
    url = f&quot;&lt;https://ieeexplore.ieee.org/xpl/conhome/9833550/proceeding?isnumber=9833558&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=1&gt;&quot;
    driver.get(url)
    #这个div 记录了pdf总数
    print(&quot;waiting for page loading&quot;)
    time.sleep(10)
    div_elements = driver.find_elements(By.CSS_SELECTOR, &#39;div.col-12.Dashboard-header.text-base-md-lh&#39;)
    total_papers= int(div_elements[0].text.split(&quot; &quot;)[-1])#204
    for page in range(1,int(total_papers/10)+2): #每页10个 /10
        url = f&quot;&lt;https://ieeexplore.ieee.org/xpl/conhome/9833550/proceeding?isnumber=9833558&amp;sortType=vol-only-seq&amp;rowsPerPage=10&amp;pageNumber=&#123;page&#125;&gt;&quot;
        print(url)
        download_page(url,driver=driver)
</code></pre>
<h3 id="NDSS"><a href="#NDSS" class="headerlink" title="NDSS"></a><strong>NDSS</strong></h3><p>使用: python <a target="_blank" rel="noopener" href="http://ndss.py/">NDSS.py</a> —year 2022</p>
<pre><code class="python">import requests
from bs4 import BeautifulSoup
import argparse
import datetime
def download_pdf(url, pdf_name):
    response = requests.get(url)
    if response.status_code == 200:
        with open(pdf_name, &#39;wb&#39;) as pdf_file:
            pdf_file.write(response.content)
        print(f&quot;Downloaded and saved &#123;pdf_name&#125;&quot;)
    else:
        print(&quot;Failed to download the PDF&quot;)

def NDSS_Download(year):
    # 定义基础URL和参数位置
    base_url = f&quot;&lt;https://www.ndss-symposium.org/ndss&#123;year&#125;/accepted-papers/&gt;&quot;  # 将URL替换为你的基础URL
    # 发起GET请求获取网页内容
    response = requests.get(base_url)
    html_content = response.text

    # 使用BeautifulSoup解析网页内容
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)

    # 查找所有匹配指定条件的链接
    links = soup.find_all(&#39;a&#39;, class_=&#39;paper-link-abs&#39;, href=True)

    # 打印匹配到的链接
    for link in links:
        paper_pdf_name=link[&#39;href&#39;].rstrip(&#39;/&#39;).split(&#39;/&#39;)[-1]
        print(&quot;Paper name:&quot;, link[&#39;href&#39;].rstrip(&#39;/&#39;).split(&#39;/&#39;)[-1])
        response = requests.get(link[&#39;href&#39;])
        html_content = response.text

        # 使用BeautifulSoup解析网页内容
        soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
        # 查找所有带有class属性为&quot;a-pdf&quot;的a标签
        pdf_links = soup.find_all(&#39;a&#39;, class_=&#39;pdf-button&#39;, href=True)[0][&#39;href&#39;]
        print(&quot;论文 url&quot;,pdf_links)

        #下载论文
        download_pdf(pdf_links, str(year)+&quot;NDSS-&quot;+paper_pdf_name+&quot;.pdf&quot;)
def USENIX_download(year):
    url_fall=&quot;&lt;https://www.usenix.org/conference/usenixsecurity21/fall-accepted-papers&gt;&quot;
    url_summer=&quot;&lt;https://www.usenix.org/conference/usenixsecurity21/summer-accepted-papers&gt;&quot;
if __name__ == &quot;__main__&quot;:
    current_year = datetime.datetime.now().year

    parser = argparse.ArgumentParser(description=&quot;Extract PDF links from a webpage based on the year.&quot;)
    parser.add_argument(&quot;--year&quot;, type=int, default=current_year, help=&quot;Year parameter (default: current year)&quot;)
    args = parser.parse_args()
    NDSS_Download(args.year)
</code></pre>
<p>多线程版本</p>
<pre><code class="python">import requests
from bs4 import BeautifulSoup
import argparse
import datetime
import threading
from concurrent.futures import ThreadPoolExecutor

def download_pdf(url, pdf_name):
    response = requests.get(url)
    if response.status_code == 200:
        with open(pdf_name, &#39;wb&#39;) as pdf_file:
            pdf_file.write(response.content)
        print(f&quot;Downloaded and saved &#123;pdf_name&#125;&quot;)
    else:
        print(&quot;Failed to download the PDF&quot;)

def download_thread(link, year):
    paper_pdf_name = link[&#39;href&#39;].rstrip(&#39;/&#39;).split(&#39;/&#39;)[-1]
    print(&quot;Paper name:&quot;, paper_pdf_name)
    response = requests.get(link[&#39;href&#39;])
    html_content = response.text

    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
    pdf_links = soup.find_all(&#39;a&#39;, class_=&#39;pdf-button&#39;, href=True)[0][&#39;href&#39;]
    print(&quot;论文 url&quot;, pdf_links)

    download_pdf(pdf_links, str(year) + &quot;NDSS-&quot; + paper_pdf_name + &quot;.pdf&quot;)

def NDSS_Download(year, num_threads):
    base_url = f&quot;&lt;https://www.ndss-symposium.org/ndss&#123;year&#125;/accepted-papers/&gt;&quot;
    response = requests.get(base_url)
    html_content = response.text
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
    links = soup.find_all(&#39;a&#39;, class_=&#39;paper-link-abs&#39;, href=True)

    # 使用线程池创建指定数量的线程
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        for link in links:
            executor.submit(download_thread, link, year)

if __name__ == &quot;__main__&quot;:
    current_year = datetime.datetime.now().year

    parser = argparse.ArgumentParser(description=&quot;Extract PDF links from a webpage based on the year.&quot;)
    parser.add_argument(&quot;--year&quot;, type=int, default=current_year, help=&quot;Year parameter (default: current year)&quot;)
    parser.add_argument(&quot;--threads&quot;, type=int, default=10, help=&quot;Number of threads (default: 10)&quot;)
    args = parser.parse_args()
    NDSS_Download(args.year, args.threads)
</code></pre>
<h3 id="USENIX"><a href="#USENIX" class="headerlink" title="USENIX"></a><strong>USENIX</strong></h3><pre><code class="python">import re

import requests
from bs4 import BeautifulSoup
import argparse
import datetime
def download_pdf(url, pdf_name):
    response = requests.get(url)
    if response.status_code == 200:
        with open(pdf_name, &#39;wb&#39;) as pdf_file:
            pdf_file.write(response.content)
        print(f&quot;Downloaded and saved &#123;pdf_name&#125;&quot;)
    else:
        print(&quot;Failed to download the PDF&quot;)

def make_safe_filename(filename):
    # 定义要替换的特殊字符的正则表达式模式
    special_chars_pattern = r&#39;[&lt;&gt;:&quot;/\\\\|?*]&#39;

    # 使用正则表达式进行替换，将特殊字符替换为下划线
    safe_filename = re.sub(special_chars_pattern, &#39;_&#39;, filename)

    return safe_filename
def USENIX_download_all(year):
    url_fall=f&quot;&lt;https://www.usenix.org/conference/usenixsecurity&#123;year&#125;/fall-accepted-papers&gt;&quot;
    USENIX_download(year,url_fall)
    url_summer=f&quot;&lt;https://www.usenix.org/conference/usenixsecurity&#123;year&#125;/summer-accepted-papers&gt;&quot;
    USENIX_download(year,url_summer)
def USENIX_download(year,url_target):
    response = requests.get(url_target)
    html_content = response.text
    # 使用BeautifulSoup解析网页内容
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
    # 查找所有匹配指定条件的链接
    pattern = re.compile(r&#39;/conference.*/presentation.*&#39;)
    links = soup.find_all(&#39;a&#39;, href=pattern)
    # 将找到的链接添加到集合中以去除重复元素
    unique_links_set = set()
    for link in links:
        unique_links_set.add(&quot;&lt;https://www.usenix.org&gt;&quot;+link[&#39;href&#39;])

    # 将集合转换回列表
    links = list(unique_links_set)
    #遍历
    for link in links:
        print(link)#&lt;https://www.usenix.org/conference/usenixsecurity23/presentation/cernera&gt;
        response = requests.get(link)
        html_content = response.text
        # 使用BeautifulSoup解析网页内容
        soup = BeautifulSoup(html_content, &#39;html.parser&#39;)

        #获取论文的标题
        pdf_name=str(year)+&quot;USENIX-&quot;+make_safe_filename(soup.find(&#39;h1&#39;, id=&#39;page-title&#39;).get_text().replace(&quot;:&quot;, &quot;&quot;))+&quot;.pdf&quot;
        #获取论文的详细链接
        pdf_link = soup.find(&#39;a&#39;, attrs=&#123;&#39;type&#39;: lambda value: value and &#39;application/pdf&#39; in value&#125;)[&#39;href&#39;]
        download_pdf(pdf_link,pdf_name)
if __name__ == &quot;__main__&quot;:
    current_year = datetime.datetime.now().year

    parser = argparse.ArgumentParser(description=&quot;Extract PDF links from a webpage based on the year.&quot;)
    parser.add_argument(&quot;--year&quot;, type=int, default=current_year, help=&quot;Year parameter (default: current year)&quot;)
    args = parser.parse_args()

    USENIX_download_all(args.year%100) #用到的是年份的后两位
</code></pre>
<p>多线程版本</p>
<pre><code class="python">import re
import requests
from bs4 import BeautifulSoup
import argparse
import datetime
from concurrent.futures import ThreadPoolExecutor
def download_pdf(url, pdf_name):
    response = requests.get(url)
    if response.status_code == 200:
        with open(pdf_name, &#39;wb&#39;) as pdf_file:
            pdf_file.write(response.content)
        print(f&quot;Downloaded and saved &#123;pdf_name&#125;&quot;)
    else:
        print(&quot;Failed to download the PDF&quot;)

def make_safe_filename(filename):
    # 定义要替换的特殊字符的正则表达式模式
    special_chars_pattern = r&#39;[&lt;&gt;:&quot;/\\\\|?*]&#39;

    # 使用正则表达式进行替换，将特殊字符替换为下划线
    safe_filename = re.sub(special_chars_pattern, &#39;_&#39;, filename)

    return safe_filename
def USENIX_download_all(year,num_threads):
    url_fall=f&quot;&lt;https://www.usenix.org/conference/usenixsecurity&#123;year&#125;/fall-accepted-papers&gt;&quot;
    USENIX_download(year,url_fall,num_threads)
    url_summer=f&quot;&lt;https://www.usenix.org/conference/usenixsecurity&#123;year&#125;/summer-accepted-papers&gt;&quot;
    USENIX_download(year,url_summer,num_threads)
def USENIX_download(year, url_target,num_threads):
    response = requests.get(url_target)
    html_content = response.text
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
    pattern = re.compile(r&#39;/conference.*/presentation.*&#39;)
    links = soup.find_all(&#39;a&#39;, href=pattern)
    unique_links_set = set()
    for link in links:
        unique_links_set.add(&quot;&lt;https://www.usenix.org&gt;&quot; + link[&#39;href&#39;])

    links = list(unique_links_set)

    # 使用线程池创建指定数量的线程
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        for link in links:
            executor.submit(download_thread, link, year)

def download_thread(link, year):
    response = requests.get(link)
    html_content = response.text
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)
    pdf_name = str(year) + &quot;USENIX-&quot; + make_safe_filename(soup.find(&#39;h1&#39;, id=&#39;page-title&#39;).get_text().replace(&quot;:&quot;, &quot;&quot;)) + &quot;.pdf&quot;
    pdf_link = soup.find(&#39;a&#39;, attrs=&#123;&#39;type&#39;: lambda value: value and &#39;application/pdf&#39; in value&#125;)[&#39;href&#39;]
    download_pdf(pdf_link, pdf_name)

if __name__ == &quot;__main__&quot;:
    current_year = datetime.datetime.now().year

    parser = argparse.ArgumentParser(description=&quot;Extract PDF links from a webpage based on the year.&quot;)
    parser.add_argument(&quot;--year&quot;, type=int, default=current_year, help=&quot;Year parameter (default: current year)&quot;)
    parser.add_argument(&quot;--threads&quot;, type=int, default=10, help=&quot;Number of threads (default: 10)&quot;)
    args = parser.parse_args()

    num_threads = args.threads
    USENIX_download_all(args.year % 100, num_threads)
</code></pre>
<h2 id="人工智能顶会"><a href="#人工智能顶会" class="headerlink" title="人工智能顶会"></a>人工智能顶会</h2><p>Download papers and supplemental materials from open-access paper website, such as <strong>AAAI</strong>, ACCV, AISTATS, COLT, CVPR, ECCV, ICCV, ICLR, <strong>ICML</strong>, <strong>IJCAI</strong>, JMLR, <strong>NIPS.</strong></p>
<p><a target="_blank" rel="noopener" href="https://github.com/SilenceEagle/paper_downloader">https://github.com/SilenceEagle/paper_downloader</a></p>
<p>github项目中有阿里云盘(2020-2022年)可直接保存下载</p>
<h3 id="下载IJCAI-2023"><a href="#下载IJCAI-2023" class="headerlink" title="下载IJCAI 2023"></a>下载IJCAI 2023</h3><p><a target="_blank" rel="noopener" href="https://www.ijcai.org/proceedings/2023/">https://www.ijcai.org/proceedings/2023/</a></p>
<p>脚本通过—year 指定年份，不输入默认为当前年份</p>
<pre><code class="python">import re

import requests
from bs4 import BeautifulSoup
import argparse
import datetime
#根据url进行下载并将文件名命名为pdf_name
def download_pdf(url, pdf_name):
    response = requests.get(url)
    if response.status_code == 200:
        with open(pdf_name, &#39;wb&#39;) as pdf_file:
            pdf_file.write(response.content)
        print(f&quot;Downloaded and saved &#123;pdf_name&#125;&quot;)
    else:
        print(&quot;Failed to download the PDF&quot;)

#有的论文有特殊字符在window下无法作为正常文件名
def make_safe_filename(filename):
    # 定义要替换的特殊字符的正则表达式模式
    special_chars_pattern = r&#39;[&lt;&gt;:&quot;/\\\\|?*]&#39;
    # 使用正则表达式进行替换，将特殊字符替换为下划线
    safe_filename = re.sub(special_chars_pattern, &#39;_&#39;, filename)

    return safe_filename
def IJCAI_download(year):
    # 定义基础URL和参数位置
    base_url = f&quot;&lt;https://www.ijcai.org/proceedings/&#123;year&#125;/&gt;&quot;  # 将URL替换为你的基础URL
    # 发起GET请求获取网页内容
    response = requests.get(base_url)
    html_content = response.text

    # 使用BeautifulSoup解析网页内容
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)

    # 查找所有匹配指定条件的链接
    links = soup.find_all(&#39;div&#39;, class_=&#39;paper_wrapper&#39;)
    for link in links:
        title=make_safe_filename(str(year)+&quot;-IJCAI-&quot;+link.find(&#39;div&#39;, class_=&#39;title&#39;).get_text()+&quot;.pdf&quot;)
        url=f&quot;&lt;https://www.ijcai.org/proceedings/&#123;year&#125;/&gt;&quot;+link.find(&#39;a&#39;, href=re.compile(r&#39;.*\\.pdf$&#39;))[&#39;href&#39;]
        print(title,url)
        download_pdf(url,title)
if __name__ == &quot;__main__&quot;:
    current_year = datetime.datetime.now().year

    parser = argparse.ArgumentParser(description=&quot;Extract PDF links from a webpage based on the year.&quot;)
    parser.add_argument(&quot;--year&quot;, type=int, default=current_year, help=&quot;Year parameter (default: current year)&quot;)
    args = parser.parse_args()

    IJCAI_download(args.year) 
</code></pre>
<h3 id="下载ICML-2023"><a href="#下载ICML-2023" class="headerlink" title="下载ICML 2023"></a>下载ICML 2023</h3><p><a target="_blank" rel="noopener" href="http://proceedings.mlr.press/">http://proceedings.mlr.press/</a></p>
<p>2023年的ICML :<a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v202/">http://proceedings.mlr.press/v202/</a></p>
<p>这个脚本只能下载2023的，后续2024之类的要将url的v202改成对应的编号</p>
<pre><code class="python">import re

import requests
from bs4 import BeautifulSoup
import argparse
import datetime
#根据url进行下载并将文件名命名为pdf_name
def download_pdf(url, pdf_name):
    response = requests.get(url)
    if response.status_code == 200:
        with open(pdf_name, &#39;wb&#39;) as pdf_file:
            pdf_file.write(response.content)
        print(f&quot;Downloaded and saved &#123;pdf_name&#125;&quot;)
    else:
        print(&quot;Failed to download the PDF&quot;)

#有的论文有特殊字符在window下无法作为正常文件名
def make_safe_filename(filename):
    # 定义要替换的特殊字符的正则表达式模式
    special_chars_pattern = r&#39;[&lt;&gt;:&quot;/\\\\|?*]&#39;
    # 使用正则表达式进行替换，将特殊字符替换为下划线
    safe_filename = re.sub(special_chars_pattern, &#39;_&#39;, filename)

    return safe_filename
def ICML_download():
    # 定义基础URL和参数位置
    base_url = &quot;&lt;http://proceedings.mlr.press/v202/&gt;&quot;
    # 发起GET请求获取网页内容
    response = requests.get(base_url)
    html_content = response.text

    # 使用BeautifulSoup解析网页内容
    soup = BeautifulSoup(html_content, &#39;html.parser&#39;)

    # 查找所有匹配指定条件的链接
    links = soup.find_all(&#39;div&#39;, class_=&#39;paper&#39;)
    for link in links:
        title=make_safe_filename(&quot;2023-ICML-&quot;+link.find(&#39;p&#39;, class_=&#39;title&#39;).get_text()+&quot;.pdf&quot;)
        url=link.find(&#39;a&#39;, href=re.compile(r&#39;.*\\.pdf$&#39;))[&#39;href&#39;]
        print(title,url)
        download_pdf(url,title)
if __name__ == &quot;__main__&quot;:
    ICML_download()
</code></pre>
<h3 id="下载AAAI-2023"><a href="#下载AAAI-2023" class="headerlink" title="下载AAAI 2023"></a>下载AAAI 2023</h3><p>zotero插件可以直接导入</p>
<p><a target="_blank" rel="noopener" href="https://dblp.uni-trier.de/db/conf/aaai/aaai2023.html">https://dblp.uni-trier.de/db/conf/aaai/aaai2023.html</a></p>
<h3 id="NIPS没有2023的"><a href="#NIPS没有2023的" class="headerlink" title="NIPS没有2023的"></a>NIPS没有2023的</h3><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2022">https://proceedings.neurips.cc/paper_files/paper/2022</a></p>
<blockquote>
<p>参考文章</p>
</blockquote>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 1944270374@qq.com </span>
    </div>
</article>







    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2020-2023 qwrdxer
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 722px;
    }
    .nav.fullscreen {
        margin-left: -722px;
    }
    .nav-left {
        width: 300px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 542px;
        }
        .nav.fullscreen {
            margin-left: -542px;
        }
        .nav-left {
            width: 150px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 542px;
            margin-left: -542px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    #post {
        background: url(/img/start.png);
    }
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
